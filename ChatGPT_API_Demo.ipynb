{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f921e8b5",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# ChatGPT and OpenAI in Python\n",
    "<!-- requirement: images/llm.png -->\n",
    "<!-- requirement: images/apikey_1.png -->\n",
    "<!-- requirement: chatgpt_template.env -->\n",
    "<!-- requirement: data/ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c23d5",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "ChatGPT is an advanced AI language model created by OpenAI. With a vast range of training data, it is designed to generate human-like text responses based on prompts and inquiries. Its capabilities span numerous topics, making it a very useful tool for generating natural language content.\n",
    "\n",
    "It can perform a wide range of tasks, including:\n",
    "- **Answering Questions**: provides information and answers on a wide variety of topics such as general knowledge, science, history, technology, etc.\n",
    "- **Language Translation**: translates text from one language to another.\n",
    "- **Text Generation**: generates human-like text for various purposes, such as writing essays, stories, poems, or even code snippets.\n",
    "- **Spell Checking and Grammar Correction**: helps identify and correct spelling mistakes or grammatical errors in text.\n",
    "- **Sentiment Analysis**: analyzes the sentiment expressed in a piece of text, determining whether it is positive, negative, or neutral.\n",
    "- **Summarization**: generates concise summaries of long articles or documents, providing the key points and main ideas.\n",
    "- **Content Creation**: helps generate ideas and content for creative writing, marketing copy, product descriptions, and more.\n",
    "- **Conversational Agent**: engages in interactive conversations, answering questions, providing suggestions, and engaging in dialogues on various topics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c75f13",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The text above is a testimony to the tasks ChatGPT can perform, as it was generated by ChatGPT when asked to describe itself and what it can be used for. If you haven't yet, feel free to play around with the [web version of ChatGPT](https://chat.openai.com/) and see for yourself what it can (and can not) do. As of the time of this writing the free web version of ChatGPT runs a GPT-3.5 model, but OpenAI has developed an upgraded GPT-4 version, which is at this moment available under paid access through ChatGPT Plus.\n",
    "\n",
    "\n",
    "For the purpose of this demonstration, we will use ChatGPT on yet another task - extracting information from a bunch of legal documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194835a",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Example: extracting information from gift agreements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2b1467",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We have a bunch of legal files, more precisely gift agreements that contain information about who gifted whom what. For  each agreement we would like to extract the names of the donor and recipient as well as what was gifted. If you browse through the files, you will see that all of the information is there, but acomplishing this task by hand would be tedious. We will instead use ChatGPT to help us.\n",
    "\n",
    "We will start by using the web version of ChatGPT, so let's do that first. We can give it a prompt like \"Extract who gifted whom what in the following agreement.\" and paste the text of one of the gift agreements.\n",
    "\n",
    "As you can probably see it works well and gives us the information we want from all the different gift agreements. \n",
    "\n",
    "How does it do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0b11f9",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Transformers: machine learning model behind the magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2402e3",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "ChatGPT, or GPT (Generative Pre-trained Transformer), is a large language model that uses a deep learning architecture called a Transformer. Transformers are a type of deep learning architecture that have significantly advanced natural language processing (NLP) tasks. They were introduced in the groundbreaking paper \"Attention Is All You Need\" by Vaswani et al. in 2017 and have since become widely used in various domains, including language translation, text generation, question answering, and more. \n",
    "\n",
    "In a nutshell a transformer model is trained to **predict the likelihood of the next word** given the previous sequence of words. GPT is trained on a massive amount of text data from the internet, including books, articles, websites, and more. This diverse dataset helps the model learn to generate grammatically correct sequences, state facts, and even display what looks like reasoning abilities.\n",
    "\n",
    "Going into the details of the model is not the focus of this demonstration, so let's just highlight that the key ingredients of transformer models that resulted in them massively outperforming models that came before are:\n",
    "- **Attention mechanism**: with very long term memory, the model has the capability to focus on different parts of the (potentally extremely long) input sentence as it generates the output.\n",
    "- **Self-attention**: allows the model to gather relevant meaning of a word from the words around it and produce more accurate representations of each word. Example: the word \"Python\" will have two different representations in the following two sentences. \"My python turned 2 years old today.\" \"Python is my favorite language.\"\n",
    "\n",
    "![LLM](images/llm.png)\n",
    "\n",
    "The transformer architecture is composed of an **encoder** and **decoder** parts. The encoder part takes in the input sequence of words (or tokens) and transforms it into a rich representation that captures the meaning and context of the input. That information is then passed to the decoder that is responsible for generating the output sequence based on the information it receives from the encoder. While the decoder in a transformer model receives the representation from the encoder as its primary input, during inference, it also incorporates its own past model outputs as input for subsequent word generation.\n",
    "\n",
    "As we mentioned, during the pre-training phase, GPT learns to predict the next token in a sequence of tokens based on the patterns it has learned from the training data. But after pre-training, the model can also undergo a process called fine-tuning. During this process is further trained on more specific tasks with labeled examples. Fine-tuning allows the model to adapt to a particular use case, such as chat-based conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97146a1f",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## OpenAI API - using ChatGPT programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce0eda",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now that we have convinced ourselves that we can solve our task with ChatGPT and have seen a bit about how it works, we would like to use it programmatically. Using the web version is fine but has some limitations, for example if we want to integrate GPT's capabilities into other applications or we simply want to process a large amount of gift contracts, we don't want to do this by copy pasting to the web interface. We'd prefer to use the API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb377f",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "OpenAI provides a [`openai`](https://github.com/openai/openai-python) Python library that will enable us to do this easily. All we need to do is make sure we have the library installed and we will need an API key. If you do not have yours yet, you can go to [this website](https://platform.openai.com/account/api-keys) and generate your API key. In case you haven't generated one yet, you will see the following:\n",
    "![generateAPIkey 1](images/apikey_1.png)\n",
    "\n",
    "After clicking on \"Create new secret key\", you can give it a name and a new API key will be generated. Make sure to copy it and keep it safe on your computer. We recommend putting it into a .env file. We created a `chatgpt_template.env` file for you here, so you can see what the file should look like. Fill your API key in the template and rename the file to `chatgpt.env`. Now we can load the key as an environment variable as you see below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c4a2b",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv('chatgpt.env') \n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a02d97",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now we are ready to make some requests. Note that if you do not add any billing options to your OpenAI account, you are using the free trial, which has a limited amount of free trial credits. You can check your usage [here](https://platform.openai.com/account/usage).\n",
    "\n",
    "One more thing, the API has two modes you can use. One is `\"completions\"` which provides the response for a single prompt. The other is `\"chat completions\"` which  provides a response to a given dialog. This means that in chat mode the input is not one single prompt, but it instead requires input in a specific format that includes the conversation history. The chat API can be used with a single prompt as well however. The main difference between these APIs at this moment are underlying GPT models that are available in each (see [here](https://platform.openai.com/docs/guides/gpt/chat-completions-vs-completions)). For our example of extracting information from gift contracts, we do not need the chat options, but because the chat completions API is the interface to the most capable model and the most cost effective model, we will use that. \n",
    "\n",
    "Let's test that this works by first using a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0f099",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "simple_prompt = 'How much is 2 + 2?'\n",
    "response = openai.ChatCompletion.create(model='gpt-3.5-turbo',\n",
    "                                        temperature=0, # degree of randomness of the output           \n",
    "                                        messages=[{'role': 'user', 'content': simple_prompt}]\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa506b",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Looks like it worked. Let's investigate the response. Notice that the output we are looking for is buried in field \"choices\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa3e315",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48581d4b",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "If we want just the result (i.e. 4), we should tell it that in the prompt. Try running above with prompt \"How much is 2 + 2? Give me just the result\".\n",
    "\n",
    "By the way, we used model \"gpt-3.5-turbo\" which is just one of the ones available. You can see all of the options [here](https://platform.openai.com/docs/models), which is a list of models that at this stage still changes quite a lot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3657430f",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We are now ready to use the API on our task of extracting info from the gift contracts. Let's write two convenience functions first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff1695",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "def generate_response(prompt, max_tokens=500):\n",
    "    \"\"\"\n",
    "    Query OpenAI API to get response.\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(model='gpt-3.5-turbo',\n",
    "                                            temperature=0, # degree of randomness of output           \n",
    "                                            messages=[{'role': 'user', 'content': prompt}]\n",
    "                                           )\n",
    "                                \n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf1c81",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "def generate_prompt(gift_contract_text):\n",
    "    \"\"\"\n",
    "    Create prompt that gets sent to OpenAI API.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'''Extract just the donor name, recipient name and the exact gift from \n",
    "                 the contract. Give the result as JSON with fields Donor, \n",
    "                 Recipient and Gift. If there are several gifts break it \n",
    "                 into a simple list of strings. {gift_contract_text}'''\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1b73c",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We decided to ask ChatGPT to give us the results in the form of JSON so we could easily process the output further if we wanted to.\n",
    "\n",
    "Let's try it on one contract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d42eb24",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "with open('data/Gift_Agreement_2431.txt', 'r') as f:\n",
    "    contract_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc900aad",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "output = generate_response(generate_prompt(contract_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5044cab5",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json.loads(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a664190c",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Looks good, we got what we wanted. We can now process all the gift agreements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fa3470",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob('data/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fde36e",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "def process_agreement(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        contract_text = f.read()\n",
    "    \n",
    "    output = generate_response(generate_prompt(contract_text))\n",
    "    \n",
    "    return json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a115cb",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "processed_agreements = [process_agreement(f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a704d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_agreements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda04d9",
   "metadata": {},
   "source": [
    "### Chat completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d6417",
   "metadata": {},
   "source": [
    "For the sake of completion, let's also demonstrate how the chat API can be used for multi-turn conversations. In this case a list of messages needs to be passed as input, where the \"user\" role refers to the user prompts and the \"assistant\" refers to ChatGPT reponses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fceac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'user', 'content': 'Hi, who was the first US president?'},\n",
    "            {'role': 'assistant', 'content': 'The first US president was George Washington.'},\n",
    "            {'role': 'user', 'content': 'When was he born? And how about the second?'}]\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e62adc4",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## ChatGPT Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c36f51",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We've seen examples where ChatGPT can be really useful and can make various NLP tasks easy. But the tool has serious limitations and potential dangers that make it unsuitable for certain types of tasks. There are legal and ethical issues related to copyright, privacy, misuse, bias, and transparency that this new technology raises. Here are some of the known issues the tool has: \n",
    "\n",
    "- Propensity for generating plausible-sounding but incorrect answers.\n",
    "- Limited knowledge and outdated information: ChatGPT's knowledge is based on pre-existing data up until September 2021. It might not have access to the most recent information or developments in various fields.\n",
    "- Bias and inappropriate responses: The training data used to develop ChatGPT contains biases present in the source material. Consequently, the model may generate biased or inappropriate responses, especially when prompted with sensitive or controversial topics.\n",
    "- Lack of contextual understanding: ChatGPT operates on a turn-by-turn basis and lacks a long-term memory of the conversation. It may sometimes provide inconsistent or incoherent responses, especially when presented with complex or multi-turn queries.\n",
    "- Sensitivity to input phrasing: The model can be highly sensitive to the way a question is phrased. Slight rephrasing of the same question may yield different responses, which can be problematic when seeking consistent and accurate information.\n",
    "- Security and privacy concerns: Sharing personal, sensitive, or confidential information with ChatGPT poses potential risks. As an AI model, it does not have inherent privacy or security safeguards, and data shared with it could be stored or used in unintended ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d341c",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "*Copyright &copy; 2023 Pragmatic Institute. This content is licensed solely for personal use. Redistribution or publication of this material is strictly prohibited.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
